{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GGMmattos/TCC-Informatica/blob/main/C%C3%B3digo_TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neyIHZ4sV7c0"
      },
      "source": [
        "# Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A6RY2jjV6-F"
      },
      "outputs": [],
      "source": [
        "\n",
        "#libs\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "import re\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from google.colab import files\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "!pip install pytorch-lightning -q\n",
        "!pip install coral_pytorch -q\n",
        "!pip install transformers==4.30.0 -q # Install a specific version of transformers\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import json # Para lidar com os embeddings salvos como string JSON\n",
        "import ast # Para avaliar strings de lista de notas\n",
        "import shlex # Para o NILC Metrix (se ainda precisar rodar o script no mesmo arquivo)\n",
        "\n",
        "# Para PyTorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n",
        "from coral_pytorch.layers import CoralLayer\n",
        "from coral_pytorch.losses import coral_loss\n",
        "from coral_pytorch.dataset import levels_from_labelbatch, proba_to_label\n",
        "\n",
        "# Para Sklearn (pré-processamento e divisão de dados)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import CSVLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Função de calculo acurácia do ENEM"
      ],
      "metadata": {
        "id": "v8cWBuX7avcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchmetrics import Metric\n",
        "from typing import Any\n",
        "\n",
        "class ENEMAccuracy(Metric):\n",
        "    def __init__(self, dist_sync_on_step=False):\n",
        "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
        "\n",
        "        # O limite de 80 pontos na escala original do ENEM\n",
        "        # corresponde a um limite de 2 na sua escala ordinal (0 a 5).\n",
        "        # A diferença absoluta máxima para ser 'não-divergente' é 2.\n",
        "        self.divergence_threshold = 2\n",
        "        self.add_state(\"non_divergent_count\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
        "        self.add_state(\"total_count\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
        "\n",
        "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
        "        # A `preds` é o tensor de rótulos previstos pelo modelo.\n",
        "        # A `target` é o tensor de rótulos verdadeiros.\n",
        "\n",
        "        # Calcula a diferença absoluta entre a previsão e o valor real\n",
        "        diff = torch.abs(preds - target)\n",
        "\n",
        "        # Conta as previsões que estão dentro do limite de divergência\n",
        "        non_divergent_batch = torch.sum(diff <= self.divergence_threshold)\n",
        "\n",
        "        self.non_divergent_count += non_divergent_batch\n",
        "        self.total_count += target.numel()\n",
        "\n",
        "    def compute(self):\n",
        "        # Calcula a precisão final como a porcentagem de previsões não-divergentes\n",
        "        return self.non_divergent_count.float() / self.total_count.float()"
      ],
      "metadata": {
        "id": "dNKkgWOtapP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al-3J8En5enw"
      },
      "source": [
        "# Importação do dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onSyJFQc9ULx"
      },
      "source": [
        "**2018-Fonseca et al**\n",
        "\n",
        "* Automatically Grading Brazilian Student Essays - NILC Metrix  - [link NILC](http://www.nilc.icmc.usp.br/nilc/projects/unitex-pb/web/dicionarios.html) -  https://github.com/nilc-nlp/nilcmetrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2J8-L1wghIM"
      },
      "source": [
        "Importação do dataset [Link](https://huggingface.co/datasets/kamel-usp/aes_enem_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ4LaR5rAIQO"
      },
      "outputs": [],
      "source": [
        "# # Login using e.g. `huggingface-cli login` to access this dataset\n",
        "# splits = {'train': 'PROPOR2024/train-00000-of-00001.parquet', 'validation': 'PROPOR2024/validation-00000-of-00001.parquet', 'test': 'PROPOR2024/test-00000-of-00001.parquet'}\n",
        "# df_train = pd.read_parquet(\"hf://datasets/kamel-usp/aes_enem_dataset/\" + splits[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TTL9FesoSgh"
      },
      "outputs": [],
      "source": [
        "#Função de ordenação\n",
        "# def natural_sort_key(s):\n",
        "#     \"\"\"\n",
        "#     Função para ordenação natural de strings que contêm números.\n",
        "#     Exemplo: ['ID10', 'ID2'] será ordenado como ['ID2', 'ID10'] em vez de ['ID10', 'ID2']\n",
        "#     \"\"\"\n",
        "#     return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
        "\n",
        "# # Ordenar o DataFrame usando a chave de ordenação natural\n",
        "# df_test = df_test.iloc[pd.Index(df_test['id_texto']).map(lambda x: natural_sort_key(x)).argsort()]\n",
        "# df_test.reset_index(drop=True, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLQ0qqkg6Dcl"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics/df_train.csv\", encoding='latin-1')\n",
        "# df_validation = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics/df_validation.csv\", encoding='latin-1')\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics/df_test.csv\", encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "gCr12oJDn9X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_validation = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/textos + NILC/df_val.csv\", encoding='latin-1',     decimal=',')\n"
      ],
      "metadata": {
        "id": "ZQXxkvtckEZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_validation['honore']"
      ],
      "metadata": {
        "id": "3M55Tjiakdug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR_HwRrx8po3",
        "outputId": "13f10024-158c-4dff-d754-05f842f5d816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(744, 203)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOqvHcLQ8w9f",
        "outputId": "c7bf694f-9a87-40b2-ca01-19b3030afe32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(195, 203)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_validation.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evewyf7P8yEG",
        "outputId": "1d60e2e8-820d-4b70-df79-be0627727870"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(216, 203)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6HO7aT3AGdZ"
      },
      "outputs": [],
      "source": [
        "# # Concatenando verticalmente\n",
        "# df = pd.concat([df_train, df_validation, df_test], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClMrxZY0A6Em"
      },
      "outputs": [],
      "source": [
        "# df.drop(columns='id_texto', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6-Y6SsnAOse",
        "outputId": "b4ae9f2d-177b-4384-d77b-600e2809f098"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1155, 202)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKD_TrGhSn0O"
      },
      "outputs": [],
      "source": [
        "# df.to_csv('df.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZYW-Jsu3RtE"
      },
      "source": [
        "# Gerando embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Importa as classes necessárias da biblioteca 'transformers'\n",
        "# from transformers import AutoTokenizer, AutoModel\n",
        "# import torch\n",
        "\n",
        "# # --- 1. Definição do Tokenizer e do Modelo ---\n",
        "# # O AutoTokenizer e o AutoModel se encarregam de carregar as configurações\n",
        "# # corretas para o modelo BERTimbau.\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "# model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "# # --- 2. Movendo para a GPU (prática recomendada) ---\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device(\"cuda\")\n",
        "#     model.to(device)\n",
        "#     print(\"Modelo BERTimbau carregado e movido para a GPU.\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "#     print(\"Modelo BERTimbau carregado e usando a CPU.\")"
      ],
      "metadata": {
        "id": "F3d8Y2pEdTmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-1Jj5cwjiNkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMWaG8XZg4kh"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataset com text + metrix\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/textos + NILC/df_test.csv\", encoding='latin-1', decimal=',')\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/textos + NILC/df_train.csv\", encoding='latin-1', decimal=',')\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/textos + NILC/df_val.csv\", encoding='latin-1', decimal=',')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxrB7tbjcjUQ",
        "outputId": "4edaf4c7-b6ed-463b-b3d4-29d49f8977a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(209, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9xfEWIFcnbw",
        "outputId": "8711d3df-72b3-416c-9f77-d2445448f96c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(758, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0EZ2Z5Bcn0A",
        "outputId": "83c5501c-2920-4228-f2ea-65039017b42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(198, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt4vD8Xm-b4D"
      },
      "source": [
        "BERTimbau (como a maioria dos BERTs base) tem um limite de 512 tokens para a entrada. Redações do ENEM geralmente são mais longas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygsu-_B18fOK"
      },
      "source": [
        "**Código para obter embedding (segmentação)**\n",
        "\n",
        "Dividir a redação em pedaços de 512 tokens, gerar um embedding para cada pedaço e depois combiná-los"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVppllive4a3"
      },
      "outputs": [],
      "source": [
        "def get_bert_embedding_segmented(text, tokenizer, model, device, max_length=512, stride=256):\n",
        "    \"\"\"\n",
        "    Gera um embedding BERT para um texto longo, utilizando segmentação e agregação.\n",
        "\n",
        "    Args:\n",
        "        text (str): O texto da redação.\n",
        "        tokenizer: O tokenizer do modelo BERT.\n",
        "        model: O modelo BERT (ex: BERTimbau).\n",
        "        device (torch.device): 'cuda' ou 'cpu'.\n",
        "        max_length (int): O tamanho máximo de cada segmento para o BERT (default: 512).\n",
        "        stride (int): O tamanho da sobreposição entre os segmentos (default: 256).\n",
        "                      Um stride menor significa mais sobreposição e possivelmente\n",
        "                      maior captura de contexto, mas mais processamento.\n",
        "\n",
        "    Returns:\n",
        "        np.array: O embedding combinado (média) de todos os segmentos, ou NaNs se o texto for nulo.\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or not isinstance(text, str): # Lidar com possíveis valores NaN ou não-string\n",
        "        return np.full((model.config.hidden_size,), np.nan) # Retorna um array de NaNs\n",
        "\n",
        "    # Tokenizar o texto completo com o retorno de IDs (para controlar a segmentação)\n",
        "    # add_special_tokens=False para não adicionar [CLS]/[SEP] no começo e fim de cada segmento\n",
        "    # pois queremos controlar isso.\n",
        "    token_ids = tokenizer.encode(text, add_special_tokens=False)\n",
        "\n",
        "    # Lista para armazenar os embeddings de cada segmento\n",
        "    segment_embeddings = []\n",
        "\n",
        "    # Iterar sobre os tokens para criar segmentos\n",
        "    # max_length - 2 para dar espaço para [CLS] e [SEP] que serão adicionados pelo tokenizer em cada segmento\n",
        "    effective_max_length = max_length - 2\n",
        "\n",
        "    # Se o texto for muito curto, trata como um único segmento (mesmo que menor que max_length)\n",
        "    if len(token_ids) <= effective_max_length:\n",
        "        segments = [token_ids]\n",
        "    else:\n",
        "        segments = []\n",
        "        for i in range(0, len(token_ids), effective_max_length - stride):\n",
        "            segment = token_ids[i : i + effective_max_length]\n",
        "            segments.append(segment)\n",
        "            # Se o último segmento for menor que o stride (não suficiente para sobreposição),\n",
        "            # ou se já chegamos ao final, paramos.\n",
        "            if i + effective_max_length >= len(token_ids):\n",
        "                break\n",
        "\n",
        "\n",
        "    # Processar cada segmento\n",
        "    for segment in segments:\n",
        "        # Adicionar os tokens especiais para cada segmento individualmente\n",
        "        # return_tensors='pt' para PyTorch\n",
        "        # truncation=True é redundante aqui se já controlamos o tamanho, mas é bom manter\n",
        "        # padding='max_length' garante que todos os segmentos tenham o mesmo tamanho de input\n",
        "        inputs = tokenizer.prepare_for_model(\n",
        "            segment,\n",
        "            add_special_tokens=True,\n",
        "            return_tensors='pt',\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True # Em caso de erro na lógica de segmentação, isso garante\n",
        "        )\n",
        "\n",
        "        # Add batch dimension to each tensor in the inputs dictionary\n",
        "        inputs = {k: v.unsqueeze(0).to(device) for k, v in inputs.items()}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Retorna o embedding do token [CLS] do segmento\n",
        "        # outputs.last_hidden_state will now have shape (batch_size, sequence_length, hidden_size)\n",
        "        # We still want the CLS token for the single item in the batch, which is index 0\n",
        "        segment_embedding = outputs.last_hidden_state[0, 0, :].cpu().numpy()\n",
        "        segment_embeddings.append(segment_embedding)\n",
        "\n",
        "    if not segment_embeddings: # Se por algum motivo nenhum embedding foi gerado (ex: texto vazio após pré-processamento)\n",
        "        return np.full((model.config.hidden_size,), np.nan)\n",
        "\n",
        "    # Combinar os embeddings dos segmentos pela média\n",
        "    combined_embedding = np.mean(segment_embeddings, axis=0)\n",
        "\n",
        "    return combined_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60QhvvivZP8Q"
      },
      "outputs": [],
      "source": [
        "# 1. Carregar o Tokenizer e o Modelo BERTimbau\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "\n",
        "# Mover o modelo para a GPU, se disponível\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.eval() # Coloca o modelo em modo de avaliação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UL04b8FeYuX"
      },
      "outputs": [],
      "source": [
        "df_val['bert_embedding'] = df_val['essay_text'].apply(\n",
        "    lambda text: get_bert_embedding_segmented(text, tokenizer, model, device, max_length=512, stride=256)\n",
        ")\n",
        "\n",
        "print(\"\\nDataFrame com embeddings BERTimbau segmentados:\")\n",
        "print(df_val.head())\n",
        "\n",
        "#Para verificar o formato do primeiro embedding:\n",
        "print(f\"\\nShape do primeiro embedding segmentado: {df_val['bert_embedding'].iloc[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgcKqkQDgnXR"
      },
      "outputs": [],
      "source": [
        "nome_do_arquivo_csv = 'df_val.csv'\n",
        "df_val.to_csv(nome_do_arquivo_csv, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpR3-rOG5sX1"
      },
      "source": [
        "# Ajuste para regressão ordinal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk1B2duXuOvp"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataset com text + metrix + embeddings\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding/df_train.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding/df_test.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding/df_val.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY9KkGjSw3c8"
      },
      "source": [
        "Processamento da coluna de notas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcclcoQNAd5X"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Converter as strings de array para listas/arrays NumPy reais\n",
        "print(\"Convertendo strings de notas (coluna 'grades') para listas de números...\")\n",
        "df_val['grades_parsed'] = df_val['grades'].apply(\n",
        "    # 1. .strip('[]') remove os colchetes\n",
        "    # 2. .split() divide por qualquer espaço em branco (um ou vários)\n",
        "    # 3. int(s) converte cada parte para inteiro\n",
        "    lambda x: [int(s) for s in x.strip('[]').split()] if isinstance(x, str) else x\n",
        ")\n",
        "print(f\"Exemplo da coluna 'grades_parsed':\\n{df_val['grades_parsed'].head()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVVGs-esBu3o"
      },
      "outputs": [],
      "source": [
        "# 2. Extrair cada nota de competência e a nota total\n",
        "print(\"Extraindo notas para cada competência e a nota total...\")\n",
        "# Nomes das colunas para as notas de competência\n",
        "competencia_cols = [f'nota_competencia_{i+1}' for i in range(5)]\n",
        "# Coluna para a nota total\n",
        "nota_total_col = 'nota_final_redacao'\n",
        "\n",
        "# Iterar para criar as colunas de competência e a nota final\n",
        "for i in range(6): # Iterar de 0 a 5 para pegar os 6 valores do vetor\n",
        "    col_name = ''\n",
        "    if i < 5:\n",
        "        col_name = competencia_cols[i]\n",
        "    else: # O sexto elemento (índice 5) é a nota total\n",
        "        col_name = nota_total_col\n",
        "\n",
        "    df_val[col_name] = df_val['grades_parsed'].apply(\n",
        "        # Verifica se é uma lista e tem o tamanho esperado (6 elementos)\n",
        "        lambda x: x[i] if isinstance(x, list) and len(x) == 6 else np.nan\n",
        "    )\n",
        "    # Garante que as notas sejam inteiras\n",
        "    df_val[col_name] = df_val[col_name].astype(int)\n",
        "\n",
        "print(\"Exemplo das novas colunas de notas de competência e total:\")\n",
        "print(df_val[competencia_cols + [nota_total_col]].head())\n",
        "print(\"\\n---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZhmKuMfhhVB",
        "outputId": "9345f001-24c5-4bf0-ba12-5e56e4ba0886"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(758, 203)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8D4NMmjCxeo"
      },
      "outputs": [],
      "source": [
        "# 4. Definir NUM_CLASSES para cada Competência e Mapeamento Ordinal\n",
        "NUM_CLASSES_COMPETENCIA = 6 # 0, 40, 80, 120, 160, 200\n",
        "\n",
        "# Mapeamento para o formato ordinal (0 a 5)\n",
        "notas_competencia_unicas = np.array([0, 40, 80, 120, 160, 200])\n",
        "mapeamento_competencia_ordinal = {nota: i for i, nota in enumerate(notas_competencia_unicas)}\n",
        "\n",
        "# Aplicar o mapeamento para cada coluna de competência\n",
        "print(f\"Mapeando notas de competência para o formato ordinal (0 a {NUM_CLASSES_COMPETENCIA-1})\")\n",
        "for col_name in competencia_cols:\n",
        "    df_val[f'{col_name}_ordinal'] = df_val[col_name].map(mapeamento_competencia_ordinal)\n",
        "\n",
        "print(\"Exemplo das notas ordinais das competências:\")\n",
        "print(df_val[[f'{col_name}_ordinal' for col_name in competencia_cols]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVoTrnJXEZkg"
      },
      "outputs": [],
      "source": [
        "nome_do_arquivo_csv = 'df_val.csv'\n",
        "df_val.to_csv(nome_do_arquivo_csv, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luqc3udpwAX5"
      },
      "source": [
        "# Configurações do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jljDWpndFd-Z"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv('/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Dataframe final/DataFrame_Final-2.0.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_KlHzR3ySjy"
      },
      "source": [
        "Configurações gerais e hiperparâmetros\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t48T7ik2JJAA"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 400\n",
        "LEARNING_RATE = 0.01\n",
        "NUM_WORKERS = 0 # Este parâmemtro pode ajudar na velocidade do treinamento não na qualidade do modelo em termos das métricas\n",
        "# Notas de competência do ENEM: 0, 40, 80, 120, 160, 200\n",
        "NUM_CLASSES_COMPETENCIA = 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQFuqVhnJn_T"
      },
      "source": [
        "**MultiLayerPerceptron**: Esta é a rede neural em \"PyTorch puro\". Ela define a arquitetura do Perceptron Multicamadas e incorpora a camada de saída especial do CORAL (CoralLayer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vw-IVQQJlhi"
      },
      "outputs": [],
      "source": [
        "class MultiLayerPerceptron(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_units, num_classes):\n",
        "        super().__init__() # Chama o construtor da classe base torch.nn.Module\n",
        "\n",
        "        # Armazena o número de classes, necessário para a função de perda CORAL\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Lista para armazenar todas as camadas da MLP\n",
        "        all_layers = []\n",
        "\n",
        "        # Loop para criar as camadas ocultas da MLP\n",
        "        # 'hidden_units' é uma tupla ou lista (ex: (256, 128, 64))\n",
        "        # Cada 'hidden_unit' representa o número de neurônios em uma camada oculta.\n",
        "        for hidden_unit in hidden_units:\n",
        "            # Cria uma camada linear (totalmente conectada)\n",
        "            # 'input_size' é o número de entradas para esta camada (saída da camada anterior ou features iniciais)\n",
        "            # 'hidden_unit' é o número de saídas desta camada\n",
        "            layer = torch.nn.Linear(input_size, hidden_unit)\n",
        "            all_layers.append(layer)\n",
        "\n",
        "            # Adiciona uma função de ativação ReLU após cada camada linear (exceto a última do CORAL)\n",
        "            all_layers.append(torch.nn.ReLU())\n",
        "\n",
        "            # Atualiza o 'input_size' para a próxima camada ser a saída da camada atual\n",
        "            input_size = hidden_unit\n",
        "\n",
        "        # --- Camada de Saída CORAL ---\n",
        "        # Esta é a principal adaptação para Regressão Ordinal com CORAL.\n",
        "        # Ao invés de uma camada linear normal (torch.nn.Linear) que retornaria um vetor de logits para classificação multiclasse,\n",
        "        # usamos a CoralLayer da biblioteca coral_pytorch.\n",
        "        # `size_in`: número de entradas para esta camada (que é a saída da última camada oculta, hidden_units[-1])\n",
        "        # `num_classes`: o número total de categorias de pontuação (ex: 6 para 0 a 200).\n",
        "        output_layer = CoralLayer(size_in=hidden_units[-1], num_classes=num_classes)\n",
        "        all_layers.append(output_layer)\n",
        "\n",
        "        # Combina todas as camadas em um modelo sequencial.\n",
        "        # 'Sequential' executa as camadas em ordem, uma após a outra.\n",
        "        self.model = torch.nn.Sequential(*all_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o fluxo de dados para frente através da rede neural.\n",
        "        `x` é o tensor de entrada (as features).\n",
        "        \"\"\"\n",
        "        # Passa o tensor de entrada através da sequência de camadas definidas\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDJYp3rfQkTH"
      },
      "source": [
        "**LightningMLP**: Esta é uma classe do PyTorch Lightning. Ela \"envolve\" a rede neural (MultiLayerPerceptron) e adiciona toda a funcionalidade extra que o Lightning oferece (treinamento automatizado, validação, teste, logs, otimizadores, etc.), tornando o código de treino muito mais limpo e padronizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZUF2Iz_QjKO"
      },
      "outputs": [],
      "source": [
        "class LightningMLP(pl.LightningModule):\n",
        "    def __init__(self, model, learning_rate):\n",
        "        super().__init__() # Chama o construtor da classe base pl.LightningModule\n",
        "\n",
        "        self.learning_rate = learning_rate # Taxa de aprendizado para o otimizador\n",
        "        self.model = model # A instância da rede neural MultiLayerPerceptron\n",
        "\n",
        "        # Salva configurações e hiperparâmetros (como learning_rate) no diretório de log.\n",
        "        # 'ignore=['model']' impede que os parâmetros do modelo sejam salvos duas vezes.\n",
        "        self.save_hyperparameters(ignore=['model'])\n",
        "\n",
        "        # MODIFICAÇÃO REALIZADA AQUI\n",
        "        # Inicializa a métrica ENEMAccuracy para cada etapa\n",
        "        self.train_enem_acc = ENEMAccuracy()\n",
        "        self.valid_enem_acc = ENEMAccuracy()\n",
        "        self.test_enem_acc = ENEMAccuracy()\n",
        "\n",
        "        self.train_rmse = torchmetrics.MeanSquaredError(squared=False)\n",
        "        self.valid_rmse = torchmetrics.MeanSquaredError(squared=False)\n",
        "        self.test_rmse = torchmetrics.MeanSquaredError(squared=False)\n",
        "\n",
        "\n",
        "        # --- Configuração das Métricas de Avaliação ---\n",
        "        # pythorthmetrics são uma forma conveniente de calcular métricas.\n",
        "        # Mean Absolute Error (MAE): Mede a diferença média absoluta entre previsões e rótulos verdadeiros.\n",
        "        self.train_mae = torchmetrics.MeanAbsoluteError()\n",
        "        self.valid_mae = torchmetrics.MeanAbsoluteError()\n",
        "        self.test_mae = torchmetrics.MeanAbsoluteError()\n",
        "\n",
        "        # Quadratic Weighted Kappa (QWK): Métrica CRUCIAL para AES.\n",
        "        # Ela considera a natureza ordinal das notas e penaliza erros maiores mais severamente.\n",
        "        # `num_classes`: número de categorias de nota (ex: 6 para competências).\n",
        "        # `task='multiclass'`: indica que é uma tarefa de classificação multi-classe (embora seja ordinal).\n",
        "        # `weights='quadratic'`: Aplica os pesos quadráticos para penalizar mais erros maiores.\n",
        "        self.train_qwk = torchmetrics.CohenKappa(num_classes=self.model.num_classes, task='multiclass', weights='quadratic')\n",
        "        self.valid_qwk = torchmetrics.CohenKappa(num_classes=self.model.num_classes, task='multiclass', weights='quadratic')\n",
        "        self.test_qwk = torchmetrics.CohenKappa(num_classes=self.model.num_classes, task='multiclass', weights='quadratic')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Define o fluxo de dados para frente através do modelo PyTorch.\n",
        "        Este método é chamado internamente pelo Lightning para fazer previsões.\n",
        "        \"\"\"\n",
        "        return self.model(x) # Simplesmente passa a entrada para o MultiLayerPerceptron\n",
        "\n",
        "    def _shared_step(self, batch):\n",
        "        \"\"\"\n",
        "        Etapa comum de processamento que é usada para treinamento, validação e teste.\n",
        "        Isso evita a duplicação de código.\n",
        "        \"\"\"\n",
        "        features, true_labels = batch # Desempacota o batch de dados\n",
        "\n",
        "        # --- Adaptação CORAL: Converter labels para o formato binário estendido ---\n",
        "        # 'levels_from_labelbatch' é uma função de coral_pytorch.\n",
        "        # Ela transforma um rótulo de classe inteira (ex: 3) em um vetor binário de \"níveis\" (ex: [1, 1, 1, 0, 0, 0])\n",
        "        # `num_classes`: o número total de classes.\n",
        "        levels = levels_from_labelbatch(\n",
        "            true_labels, num_classes=self.model.num_classes)\n",
        "\n",
        "        # Passa as features para a rede neural para obter os logits (saídas brutas)\n",
        "        logits = self(features) # self(features) é o mesmo que self.forward(features)\n",
        "\n",
        "        # --- Adaptação CORAL: Calcular a função de perda CORAL ---\n",
        "        # 'coral_loss' é uma função de coral_pytorch.\n",
        "        # Ela calcula a perda entre os logits do modelo e os 'levels' binários.\n",
        "        # 'levels.type_as(logits)' garante que os tipos de dados dos tensores sejam compatíveis.\n",
        "        loss = coral_loss(logits, levels.type_as(logits))\n",
        "\n",
        "        # --- Adaptação CORAL: Converter probabilidades previstas em rótulos finais ---\n",
        "        # `torch.sigmoid(logits)`: Transforma os logits brutos em probabilidades entre 0 e 1.\n",
        "        # `proba_to_label`: Uma função de coral_pytorch que converte essas probabilidades\n",
        "        # em rótulos de classe previstos (ex: 0, 1, 2, ..., num_classes-1).\n",
        "        probas = torch.sigmoid(logits)\n",
        "        predicted_labels = proba_to_label(probas)\n",
        "\n",
        "        return loss, true_labels, predicted_labels\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Define o que acontece em cada passo de treinamento (para cada batch).\n",
        "        \"\"\"\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch) # Usa a etapa compartilhada\n",
        "\n",
        "        # MODIFICADO AQUI\n",
        "        self.train_enem_acc(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"train_enem_acc\", self.train_enem_acc, on_epoch=True, on_step=False)\n",
        "\n",
        "        # Registrar a perda de treinamento\n",
        "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False) # 'on_epoch=True' loga no final da epoch\n",
        "\n",
        "        # Calcular e registrar o MAE de treinamento\n",
        "        self.train_mae(predicted_labels, true_labels)\n",
        "        self.log(\"train_mae\", self.train_mae, on_epoch=True, on_step=False)\n",
        "\n",
        "        # Calcular e registrar o QWK de treinamento\n",
        "        self.train_qwk(predicted_labels, true_labels)\n",
        "        self.log(\"train_qwk\", self.train_qwk, on_epoch=True, on_step=False)\n",
        "\n",
        "        # --- Adição do RMSE em training_step ---\n",
        "        self.train_rmse(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"train_rmse\", self.train_rmse, on_epoch=True, on_step=False)\n",
        "\n",
        "        return loss  # A perda é retornada para o otimizador fazer o backpropagation\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Define o que acontece em cada passo de validação.\n",
        "        Similar ao training_step, mas não calcula gradientes.\n",
        "        \"\"\"\n",
        "        loss, true_labels, predicted_labels = self._shared_step(batch)\n",
        "\n",
        "        # MODIFICADO AQUI\n",
        "        self.valid_enem_acc(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"valid_enem_acc\", self.valid_enem_acc, on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "        self.log(\"valid_loss\", loss, on_epoch=True, on_step=False)\n",
        "        self.valid_mae(predicted_labels, true_labels)\n",
        "\n",
        "        self.log(\"valid_mae\", self.valid_mae,on_epoch=True, on_step=False, prog_bar=True) # prog_bar mostra no progresso da barra\n",
        "        self.valid_qwk(predicted_labels, true_labels)\n",
        "\n",
        "        self.log(\"valid_qwk\", self.valid_qwk,on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "  # --- Adição do RMSE em validation_step ---\n",
        "        self.valid_rmse(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"valid_rmse\", self.valid_rmse, on_epoch=True, on_step=False, prog_bar=True)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        Define o que acontece em cada passo de teste (avaliação final).\n",
        "        \"\"\"\n",
        "        # Não precisamos da perda para o teste, por isso o '_'\n",
        "        _, true_labels, predicted_labels = self._shared_step(batch)\n",
        "\n",
        "        self.test_enem_acc(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"test_enem_acc\", self.test_enem_acc, on_epoch=True, on_step=False)\n",
        "\n",
        "        self.test_mae(predicted_labels, true_labels)\n",
        "        self.log(\"test_mae\", self.test_mae, on_epoch=True, on_step=False)\n",
        "\n",
        "        self.test_qwk(predicted_labels, true_labels)\n",
        "        self.log(\"test_qwk\", self.test_qwk, on_epoch=True, on_step=False)\n",
        "\n",
        "        self.test_rmse(predicted_labels.float(), true_labels.float())\n",
        "        self.log(\"test_rmse\", self.test_rmse, on_epoch=True, on_step=False)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        Configura o otimizador da rede neural.\n",
        "        \"\"\"\n",
        "        # Otimizador Adam: otimizador popular e eficiente.\n",
        "        # self.parameters() retorna todos os parâmetros treináveis do modelo.\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWi00SZEKIm0"
      },
      "source": [
        "**Classe MyDataset**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANmyRtDfKQXy"
      },
      "source": [
        "Este código define a classe MyDataset, que prepara os dados para o PyTorch. Ele armazena as features (X) e labels (y) em arrays NumPy. Os métodos **__len__** e **__getitem__** permitem que o PyTorch saiba o tamanho total do seu dataset e como acessar cada amostra individualmente (features e seu label correspondente) usando um índice. Isso é fundamental para organizar os dados para o treinamento do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hIBxbqLKGvy"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset): # A classe MyDataset herda de torch.utils.data.Dataset\n",
        "    def __init__(self, feature_array, label_array, dtype=np.float32):\n",
        "        \"\"\"\n",
        "        Método construtor da classe. É chamado quando você cria uma nova instância de MyDataset.\n",
        "\n",
        "        Args:\n",
        "            feature_array (np.ndarray): Um array NumPy contendo suas features (X).\n",
        "                                        Por exemplo, X_train_std, X_val_std, X_test_std.\n",
        "            label_array (np.ndarray): Um array NumPy contendo seus labels (y).\n",
        "                                      Por exemplo, y_train, y_val, y_test.\n",
        "            dtype (np.float32, optional): O tipo de dado em que as features serão convertidas.\n",
        "                                          np.float32 é um tipo comum para entradas de redes neurais,\n",
        "                                          pois economiza memória e é compatível com GPUs.\n",
        "        \"\"\"\n",
        "        # Converte o array de features para o tipo de dado especificado.\n",
        "        # Isso é importante para garantir que as features estejam no formato numérico\n",
        "        # esperado pelo PyTorch (geralmente float32 ou float64).\n",
        "        self.feature_data = feature_array.astype(dtype)\n",
        "\n",
        "        # Armazena o array de labels.\n",
        "        # Comentário: \"Labels devem ser long para PyTorch\" -- isso é uma dica importante.\n",
        "        # Para problemas de classificação (e regressão ordinal como no presente trabalho, que usa classificadores binários internamente),\n",
        "        # o PyTorch geralmente espera que os rótulos de classe sejam tensores do tipo Long (torch.long).\n",
        "        # Se label_array for um NumPy array de inteiros, PyTorch lida com isso.\n",
        "        self.labels = label_array\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Método mágico que permite acessar amostras do dataset usando índices, como em uma lista.\n",
        "        Ex: dataset[0] chamaria __getitem__(0).\n",
        "\n",
        "        Args:\n",
        "            index (int): O índice da amostra que você deseja retornar.\n",
        "\n",
        "        Returns:\n",
        "            tuple: Uma tupla contendo (inputs, label) para a amostra no índice fornecido.\n",
        "                   - inputs: As features (dados de entrada) da amostra.\n",
        "                   - label: O rótulo (valor alvo) correspondente à amostra.\n",
        "        \"\"\"\n",
        "        inputs = self.feature_data[index] # Pega a linha de features no 'index'\n",
        "        label = self.labels[index]   # Pega o label correspondente no 'index'\n",
        "        return inputs, label\n",
        "\n",
        "    def __len__(self, ):\n",
        "        \"\"\"\n",
        "        Método mágico que retorna o número total de amostras no dataset.\n",
        "        Permite usar len(dataset).\n",
        "\n",
        "        Returns:\n",
        "            int: O número de linhas (amostras) no array de features.\n",
        "        \"\"\"\n",
        "        return self.feature_data.shape[0] # Retorna o número de linhas (primeira dimensão) do array de features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCznS31CKXXC"
      },
      "source": [
        "**Classe CompetenceDataModule (Substitui DataModule)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyosnL3NKiBK"
      },
      "source": [
        "Esta é a parte central da adaptação para múltiplos modelos. O DataModule agora será específico para cada competência, recebendo os X e y já divididos e escalados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU7iHhkUKaYS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "class CompetenceDataModule(pl.LightningDataModule): # A classe herda de pytorch_lightning.LightningDataModule\n",
        "    def __init__(self, X_train, y_train, X_val, y_val, X_test, y_test, batch_size, num_workers):\n",
        "        \"\"\"\n",
        "        Método construtor da classe. É chamado quando é criado uma nova instância de CompetenceDataModule.\n",
        "\n",
        "        Args:\n",
        "            X_train (np.ndarray): Matriz de features para o conjunto de treinamento.\n",
        "            y_train (np.ndarray): Vetor de labels (notas) para o conjunto de treinamento.\n",
        "            X_val (np.ndarray): Matriz de features para o conjunto de validação.\n",
        "            y_val (np.ndarray): Vetor de labels para o conjunto de validação.\n",
        "            X_test (np.ndarray): Matriz de features para o conjunto de teste.\n",
        "            y_test (np.ndarray): Vetor de labels para o conjunto de teste.\n",
        "            batch_size (int): O número de amostras por lote (batch) que o modelo processará de cada vez.\n",
        "            num_workers (int): O número de subprocessos a serem usados para carregamento de dados.\n",
        "                                0 significa que o carregamento será feito no processo principal.\n",
        "                                Valores > 0 podem acelerar o carregamento, mas podem causar problemas em ambientes como o Windows/WSL.\n",
        "        \"\"\"\n",
        "        super().__init__() # Chama o construtor da classe base pl.LightningDataModule\n",
        "\n",
        "        # Armazena os arrays NumPy dos conjuntos de dados\n",
        "        # Esses dados já devem estar pré-processados e escalados (ex: X_train_std)\n",
        "        # self.X_train = X_train\n",
        "        # self.y_train = y_train\n",
        "        # self.X_val = X_val\n",
        "        # self.y_val = y_val\n",
        "        # self.X_test = X_test\n",
        "        # self.y_test = y_test\n",
        "\n",
        "        self.X_train = torch.FloatTensor(X_train)\n",
        "        self.y_train = torch.IntTensor(y_train)  # ou IntTensor dependendo do seu caso\n",
        "        self.X_val = torch.FloatTensor(X_val)\n",
        "        self.y_val = torch.IntTensor(y_val)\n",
        "        self.X_test = torch.FloatTensor(X_test)\n",
        "        self.y_test = torch.IntTensor(y_test)\n",
        "\n",
        "        # Armazena configurações de DataLoader\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        \"\"\"\n",
        "        Este método é chamado pelo PyTorch Lightning para preparar os dados.\n",
        "        Ele é chamado em cada \"nó\" (processo/GPU) em um ambiente distribuído.\n",
        "        Normalmente, é aqui que fazemos a divisão de dados, escalamento, etc.\n",
        "        Em nosso caso caso, ja fizemos isso no fluxo principal do script, então aqui ele\n",
        "        apenas cria as instâncias de MyDataset.\n",
        "\n",
        "        Args:\n",
        "            stage (str, optional): Indica a fase atual ('fit', 'validate', 'test', 'predict').\n",
        "                                   Permite lógica condicional se necessário. Ignorado aqui.\n",
        "        \"\"\"\n",
        "        # Cria os objetos MyDataset para cada conjunto (treino, validação, teste).\n",
        "        # MyDataset encapsula os arrays NumPy X e y em um formato que PyTorch pode usar.\n",
        "        # self.train = MyDataset(self.X_train, self.y_train)\n",
        "        # self.valid = MyDataset(self.X_val, self.y_val)\n",
        "        # self.test = MyDataset(self.X_test, self.y_test)\n",
        "\n",
        "        self.train = TensorDataset(self.X_train, self.y_train)\n",
        "        self.valid = TensorDataset(self.X_val, self.y_val)\n",
        "        self.test = TensorDataset(self.X_test, self.y_test)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"\n",
        "        Retorna o DataLoader para o conjunto de treinamento.\n",
        "        \"\"\"\n",
        "        return DataLoader(self.train,\n",
        "                          batch_size=self.batch_size, # Tamanho dos lotes para o treino\n",
        "                          num_workers=self.num_workers, # Número de subprocessos para carregar dados\n",
        "                          shuffle=True, # Embaralha os dados a cada epoch para evitar que o modelo \"decore\" a ordem\n",
        "                          drop_last=True) # Se o último batch não tiver o tamanho completo, ele é descartado.\n",
        "                                          # Útil para modelos que esperam batches de tamanho fixo, ou GPUs.\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"\n",
        "        Retorna o DataLoader para o conjunto de validação.\n",
        "        \"\"\"\n",
        "        return DataLoader(self.valid,\n",
        "                          batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers,\n",
        "                          drop_last=True) # Explicitly set drop_last to True for validation\n",
        "                          # shuffle=False é o padrão para validação/teste, pois a ordem não importa.\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        \"\"\"\n",
        "        Retorna o DataLoader para o conjunto de teste.\n",
        "        \"\"\"\n",
        "        return DataLoader(self.test,\n",
        "                          batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers)\n",
        "                          # shuffle=False é o padrão para validação/teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAt8GrhA8fin"
      },
      "source": [
        "# Importação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBwJxKz-8nKW"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df com métrica NILC/df_validation.csv\")\n"
      ],
      "metadata": {
        "id": "GlqH8ENZe974"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['honore']"
      ],
      "metadata": {
        "id": "8uSezWDZfElH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWNec_aT8vNY"
      },
      "source": [
        "# Análise de divergência (test_hard and test_easy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do Tipo de Análise:\n",
        "# Valores de 0 a 4: Competências do ENEM (C1 a C5)\n",
        "# Valor 5: Nota final (soma das competências)\n",
        "REFERENCE_CONCEPT = 4"
      ],
      "metadata": {
        "id": "I92Dgs5tvFcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"kamel-usp/aes_enem_dataset\", \"sourceAWithGraders\", cache_dir=\"/tmp/aes_enem\", trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480,
          "referenced_widgets": [
            "ddf913a04e1448e0a20ff2475c90371c",
            "33ddb8eaee5840ffb7354cbd2739a3fd",
            "4560345e9fe34f0cac020647be8bf097",
            "4638a22cf9d14283a3183c56427787c7",
            "f71eafd10c1d4a4dab3562880aac0add",
            "04e192c36a5e4e44bfcfdb1011cf7976",
            "9e3fb699c8794ec3a2eca967bdd751d1",
            "0252174812724a73885e663710af5505",
            "ca826f84b25c422790f84ffb31b938d2",
            "ba599b2e91d143148e8f191668af6630",
            "f27e6f567b094ecfad52072c120a49ee",
            "41fbed63d24d4930bba2be31842a8e15",
            "178ed08adee54dc0bd884f7bde781f3d",
            "d9e39bbef0934a5d9c7d844812a54102",
            "f264678305a84e998529df9e6d029bc8",
            "c50e994e93524687946bb075b31f5de5",
            "2d95282c73b946b6a29932cd4014c80b",
            "2280c4e64ac94e918160e94b3b189e97",
            "7177bfe381964370a34912158506fd18",
            "e1a2dc165bed44b1952815fa6af4ce20",
            "aa51267bfb5c42b5b26e560d64e58ea0",
            "f4595f36fadc4d53ba53a0f88f1706a1",
            "cecff74e4d2b42b1a7a77295fbd4c432",
            "83d15e315ebe4d1b947ea63a36ed29cc",
            "d4bfc9b6ea694fecbc452cfa4f8c8bca",
            "47593ada5106488b9298fe2a35782b9b",
            "3b19d6393f2249d190d3013f175f4bb6",
            "059ee0ef13b246588b1c9b25218f9711",
            "92cb0bcd5a2f4e278f485aba0c68e0f4",
            "1e35b1c576944e31a4381ec2bf33fb78",
            "8607fd04cdf54eba90ca0fc04dc1c1ee",
            "beccb68f585b495d808a210a6025084c",
            "c75ddb474a2845bf966511dfadda079c",
            "3d601a182de648539a3c1b6985088721",
            "34608d5a1bd44199a20123dc4e206057",
            "fb35f5ce50454525a2378421caa001ca",
            "37fd4e2a817344f081cf34e9e33f760e",
            "5baeb20a1e324783805125e65b84085a",
            "a0d5f852db6440d387ea9fb1f5986e88",
            "f1a0170205a04034ae148579cf03774c",
            "5e641d7696864983a76c3e3131885144",
            "b1fe54a67ca74122ab06b3ef5921fca6",
            "a5d3faf6be0b44f583cb18fff98a5079",
            "cbae534709cf432dbdd7ae241cb38b5e",
            "83625cf9a4f541489b9340628b969c80",
            "cb0f90396e644e9681016b24bcf403ee",
            "408c8ffb515341d7a315ec9cd67190fd",
            "6f85d79ac9134876953fe16224a64025",
            "8d9acd0f4364414a8694fa7d38d7a1c5",
            "2ec4a6dbccb34618bdd574b507e21c34",
            "fe295d967e7f4df4bfa53ee7dd418229",
            "a7d01718dffd46d786f3d44f55cf22ad",
            "05eff5d01a634ebab68ab6507df53c89",
            "c52f7ee14caf403a9b352ac9ee861f7e",
            "6adfb288487b46c190879e4a98577e56",
            "51e5e7e13fbf4d83afa48b0da5ad36fc",
            "03b927f95f3d489b900252ceb552c9c3",
            "9f2876c84ef84852988bed8096eb240a",
            "a41308c1b1ba47bda8343b2f8db7283c",
            "b32ccd0775d0413f86aceef124fb78f5",
            "5881870aa125482eab86f48b816efec2",
            "e84ce443daba47ef9da780069017f040",
            "1e1fe32865a44975bb0f1ae981ceb1ab",
            "70f4e504680e41b4aee3a63509f257f0",
            "7ff39f37d48b4cee89dcddb6a41f3d19",
            "bd5a681dd223428290b7ef96e94b977f",
            "f29814ca434e49abbe70bbf35d69d54c",
            "edb419b75a5b405b9eed9d07d4c7b47e",
            "416190b0f97e4509a502c68fe116a55a",
            "93eec2d156d04eff9329e3facc509db9",
            "3bcc7151c37742619930e3f2e19f7539",
            "8aa9997173414fb89278a8765102a8d3",
            "c084df03093d4e03ad9a987773933b78",
            "fdf66fe5b26247b18085ab22ef3a8145",
            "71e9fb2e393f413f9ecea75bec5b9498",
            "72402864b0e24a79b58b4cae8f4f3fdd",
            "4531c383dbcf4d1b9c57a80883dcbf6d"
          ]
        },
        "id": "Mans7jB7s3X2",
        "outputId": "c96881db-8767-410e-a2f6-9ff644af88f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'kamel-usp/aes_enem_dataset' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'kamel-usp/aes_enem_dataset' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddf913a04e1448e0a20ff2475c90371c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sourceAWithGraders/train-00000-of-00001.(…):   0%|          | 0.00/589k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41fbed63d24d4930bba2be31842a8e15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sourceAWithGraders/validation-00000-of-0(…):   0%|          | 0.00/163k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cecff74e4d2b42b1a7a77295fbd4c432"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sourceAWithGraders/test-00000-of-00001.p(…):   0%|          | 0.00/178k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d601a182de648539a3c1b6985088721"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/758 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83625cf9a4f541489b9340628b969c80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/198 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51e5e7e13fbf4d83afa48b0da5ad36fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/209 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f29814ca434e49abbe70bbf35d69d54c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4lGrHGn80Q7"
      },
      "outputs": [],
      "source": [
        "def computa_diferenca(lists):\n",
        "    \"\"\"Identifica redações com grande divergência entre avaliadores (>80 pontos)\"\"\"\n",
        "    if len(lists) < 3:\n",
        "        return False\n",
        "\n",
        "    referencia = lists[0][REFERENCE_CONCEPT]\n",
        "    avaliador_a = lists[1][REFERENCE_CONCEPT]\n",
        "    avaliador_b = lists[2][REFERENCE_CONCEPT]\n",
        "\n",
        "    diff_ref_a = abs(referencia - avaliador_a)\n",
        "    diff_ref_b = abs(referencia - avaliador_b)\n",
        "    diff_a_b = abs(avaliador_a - avaliador_b)\n",
        "\n",
        "    return diff_ref_a > 80 or diff_ref_b > 80 or diff_a_b > 80"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separação em conjuntos easy/hard\n",
        "test_df = dataset[\"test\"].to_pandas()\n",
        "\n",
        "new_test_df = pd.merge(\n",
        "    test_df.groupby([\"id_prompt\", \"id\"])\n",
        "           .agg({\"grades\": list})\n",
        "           .apply(lambda x: computa_diferenca(x['grades']), axis=1)\n",
        "           .reset_index(),\n",
        "    test_df,\n",
        "    on=[\"id_prompt\", \"id\"]\n",
        ").rename(columns={0: \"is_hard\"})"
      ],
      "metadata": {
        "id": "dtvO-LnixhAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# O restante do seu código...\n",
        "dataset[\"test_easy\"] = Dataset.from_pandas(new_test_df[new_test_df[\"is_hard\"]==False])\n",
        "dataset[\"test_hard\"] = Dataset.from_pandas(new_test_df[new_test_df[\"is_hard\"]==True])"
      ],
      "metadata": {
        "id": "xlZricHBye53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Cria o DataFrame de Redações Fáceis (is_hard == False)\n",
        "df_test_easy = new_test_df[new_test_df[\"is_hard\"] == False].copy()\n",
        "\n",
        "# 2. Cria o DataFrame de Redações Difíceis (is_hard == True)\n",
        "df_test_hard = new_test_df[new_test_df[\"is_hard\"] == True].copy()\n",
        "\n",
        "# Exibe os tamanhos dos novos conjuntos para verificação\n",
        "print(f\"DataFrame EASY criado. Tamanho: {len(df_test_easy)}\")\n",
        "print(f\"DataFrame HARD criado. Tamanho: {len(df_test_hard)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYsJ0g5Gy9V_",
        "outputId": "3be62236-3574-4665-b6d5-9c38859dd22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame EASY criado. Tamanho: 173\n",
            "DataFrame HARD criado. Tamanho: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/test_murilo.csv\")"
      ],
      "metadata": {
        "id": "-1pLh5y3FCAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_test['id'] = range(len(df_test))\n",
        "df_test_easy['id'] = range(len(df_test_easy))\n",
        "df_test_hard['id'] = range(len(df_test_hard))"
      ],
      "metadata": {
        "id": "Pk2j49J2GcTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "textos_easy = df_test_easy['id'].unique()\n",
        "textos_hard = df_test_hard['id'].unique()\n",
        "\n",
        "# 2. Criar os novos DataFrames (df_final_easy e df_final_hard) a partir do df_test principal\n",
        "# Usamos o método .isin() para filtrar o df_test principal pelas chaves de texto.\n",
        "\n",
        "# Filtrar as redações \"fáceis\"\n",
        "df_final_easy = df_test[df_test['id'].isin(textos_easy)].copy()\n",
        "\n",
        "# Filtrar as redações \"difíceis\"\n",
        "df_final_hard = df_test[df_test['id'].isin(textos_hard)].copy()\n",
        "\n",
        "# 3. Verificação dos tamanhos e da integridade dos dados\n",
        "print(\"Separação concluída com o df_test como fonte:\")\n",
        "print(f\"df_final_easy (Baixa Divergência): {len(df_final_easy)} registros\")\n",
        "print(f\"df_final_hard (Alta Divergência): {len(df_final_hard)} registros\")\n",
        "\n",
        "# Verificação da soma\n",
        "soma_total = len(df_final_easy) + len(df_final_hard)\n",
        "print(f\"Soma das partições: {soma_total} (Deve ser 209)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY8xH4NZDfYD",
        "outputId": "9c0fd442-5022-47ed-996a-bdf400db259f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Separação concluída com o df_test como fonte:\n",
            "df_final_easy (Baixa Divergência): 173 registros\n",
            "df_final_hard (Alta Divergência): 36 registros\n",
            "Soma das partições: 209 (Deve ser 209)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nome_do_arquivo_csv = 'df_test_easy.csv'\n",
        "df_final_easy.to_csv(nome_do_arquivo_csv, index=False)"
      ],
      "metadata": {
        "id": "sYL1eGqjJa9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nome_do_arquivo_csv = 'df_test_hard.csv'\n",
        "df_final_hard.to_csv(nome_do_arquivo_csv, index=False)"
      ],
      "metadata": {
        "id": "-CMCw1D2Jc1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_easy.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "qNHtmjET2x0_",
        "outputId": "c3158d0b-ac4e-4f53-c694-5486ed851a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          essay_text  \\\n",
              "0  A questão do atual governo brasileiro liberar ...   \n",
              "1  A homofobia vem aumentando diariamente, pratic...   \n",
              "2  É rotineira e comovente as cenas de imigrantes...   \n",
              "3  É notório que a legalização sem limites dos pe...   \n",
              "4  O economista Thomas Malthus, em sua teoria des...   \n",
              "\n",
              "                      grades   adjective_ratio  adverbs  content_words  \\\n",
              "0  [ 80  80  80  80  80 400]           0.11074  0.06711        0.60403   \n",
              "1  [160  40  40 120  40 400]           0.07034  0.06116        0.59327   \n",
              "2  [120 120 160 160   0 560]           0.06918  0.04088        0.58176   \n",
              "3  [160 120 120 120  80 600]           0.11917  0.04145        0.56995   \n",
              "4  [120  40  40 160  40 400]           0.06923  0.03846        0.56154   \n",
              "\n",
              "     flesch  function_words  sentences_per_paragraph  \\\n",
              "0  37.30584         0.39597                      2.8   \n",
              "1  34.38359         0.40673                      2.4   \n",
              "2  23.68850         0.41824                      2.2   \n",
              "3  27.53258         0.43005                      2.0   \n",
              "4   4.08936         0.43846                      1.5   \n",
              "\n",
              "   syllables_per_content_word  words_per_sentence  ...  nota_competencia_3  \\\n",
              "0                     2.87222            21.28571  ...                  80   \n",
              "1                     2.82990            27.25000  ...                  40   \n",
              "2                     3.09730            28.90909  ...                 160   \n",
              "3                     3.16364         24125.00000  ...                 120   \n",
              "4                     3.26027            43.33333  ...                  40   \n",
              "\n",
              "   nota_competencia_4  nota_competencia_5  nota_final_redacao  \\\n",
              "0                  80                  80                 400   \n",
              "1                 120                  40                 400   \n",
              "2                 160                   0                 560   \n",
              "3                 120                  80                 600   \n",
              "4                 160                  40                 400   \n",
              "\n",
              "   nota_competencia_1_ordinal  nota_competencia_2_ordinal  \\\n",
              "0                           2                           2   \n",
              "1                           4                           1   \n",
              "2                           3                           3   \n",
              "3                           4                           3   \n",
              "4                           3                           1   \n",
              "\n",
              "   nota_competencia_3_ordinal  nota_competencia_4_ordinal  \\\n",
              "0                           2                           2   \n",
              "1                           1                           3   \n",
              "2                           4                           4   \n",
              "3                           3                           3   \n",
              "4                           1                           4   \n",
              "\n",
              "   nota_competencia_5_ordinal  id  \n",
              "0                           2   0  \n",
              "1                           1   1  \n",
              "2                           0   2  \n",
              "3                           2   3  \n",
              "4                           1   4  \n",
              "\n",
              "[5 rows x 216 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d29a6af0-34cb-49e3-8559-b25bbcfb51da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_text</th>\n",
              "      <th>grades</th>\n",
              "      <th>adjective_ratio</th>\n",
              "      <th>adverbs</th>\n",
              "      <th>content_words</th>\n",
              "      <th>flesch</th>\n",
              "      <th>function_words</th>\n",
              "      <th>sentences_per_paragraph</th>\n",
              "      <th>syllables_per_content_word</th>\n",
              "      <th>words_per_sentence</th>\n",
              "      <th>...</th>\n",
              "      <th>nota_competencia_3</th>\n",
              "      <th>nota_competencia_4</th>\n",
              "      <th>nota_competencia_5</th>\n",
              "      <th>nota_final_redacao</th>\n",
              "      <th>nota_competencia_1_ordinal</th>\n",
              "      <th>nota_competencia_2_ordinal</th>\n",
              "      <th>nota_competencia_3_ordinal</th>\n",
              "      <th>nota_competencia_4_ordinal</th>\n",
              "      <th>nota_competencia_5_ordinal</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A questão do atual governo brasileiro liberar ...</td>\n",
              "      <td>[ 80  80  80  80  80 400]</td>\n",
              "      <td>0.11074</td>\n",
              "      <td>0.06711</td>\n",
              "      <td>0.60403</td>\n",
              "      <td>37.30584</td>\n",
              "      <td>0.39597</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.87222</td>\n",
              "      <td>21.28571</td>\n",
              "      <td>...</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>80</td>\n",
              "      <td>400</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A homofobia vem aumentando diariamente, pratic...</td>\n",
              "      <td>[160  40  40 120  40 400]</td>\n",
              "      <td>0.07034</td>\n",
              "      <td>0.06116</td>\n",
              "      <td>0.59327</td>\n",
              "      <td>34.38359</td>\n",
              "      <td>0.40673</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.82990</td>\n",
              "      <td>27.25000</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>120</td>\n",
              "      <td>40</td>\n",
              "      <td>400</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>É rotineira e comovente as cenas de imigrantes...</td>\n",
              "      <td>[120 120 160 160   0 560]</td>\n",
              "      <td>0.06918</td>\n",
              "      <td>0.04088</td>\n",
              "      <td>0.58176</td>\n",
              "      <td>23.68850</td>\n",
              "      <td>0.41824</td>\n",
              "      <td>2.2</td>\n",
              "      <td>3.09730</td>\n",
              "      <td>28.90909</td>\n",
              "      <td>...</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>0</td>\n",
              "      <td>560</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>É notório que a legalização sem limites dos pe...</td>\n",
              "      <td>[160 120 120 120  80 600]</td>\n",
              "      <td>0.11917</td>\n",
              "      <td>0.04145</td>\n",
              "      <td>0.56995</td>\n",
              "      <td>27.53258</td>\n",
              "      <td>0.43005</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.16364</td>\n",
              "      <td>24125.00000</td>\n",
              "      <td>...</td>\n",
              "      <td>120</td>\n",
              "      <td>120</td>\n",
              "      <td>80</td>\n",
              "      <td>600</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O economista Thomas Malthus, em sua teoria des...</td>\n",
              "      <td>[120  40  40 160  40 400]</td>\n",
              "      <td>0.06923</td>\n",
              "      <td>0.03846</td>\n",
              "      <td>0.56154</td>\n",
              "      <td>4.08936</td>\n",
              "      <td>0.43846</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.26027</td>\n",
              "      <td>43.33333</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>160</td>\n",
              "      <td>40</td>\n",
              "      <td>400</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 216 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d29a6af0-34cb-49e3-8559-b25bbcfb51da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d29a6af0-34cb-49e3-8559-b25bbcfb51da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d29a6af0-34cb-49e3-8559-b25bbcfb51da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2e593b31-78d9-4365-bc05-b3adeb9be990\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e593b31-78d9-4365-bc05-b3adeb9be990')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2e593b31-78d9-4365-bc05-b3adeb9be990 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final_easy"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ovNBO7qs52Y"
      },
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCTT2RkYbvC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d5bad4-856e-4c7d-a682-a0f43d6a5ed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Aqui garantimos que lista de stop words do NLTK esteja disponível\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iVai53FUspO"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\")\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_easy.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM17JDOy4PhC",
        "outputId": "e1bb2cb7-a812-4259-8bf7-3ed231a53bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(173, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycYe31cA4TFc",
        "outputId": "3e3ed8f1-1665-4b56-f69c-80d1639c6d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(758, 216)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P9x27gB4ZWO",
        "outputId": "2c4cb107-35f8-4df4-af81-1528ca9e4fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(198, 215)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N_5ZhID4ps0",
        "outputId": "b57f1562-9c36-46f1-c828-00dee6bafcef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(209, 215)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXZYCu7Pd2Mt"
      },
      "outputs": [],
      "source": [
        "# Pré-processmaento dos textos\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    stop_words_pt = set(stopwords.words('portuguese'))\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words_pt])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FvP75Ivh-RX"
      },
      "outputs": [],
      "source": [
        "df_train['processed_text'] = df_train['essay_text'].apply(preprocess_text)\n",
        "df_test['processed_text'] = df_test['essay_text'].apply(preprocess_text)\n",
        "df_val['processed_text'] = df_val['essay_text'].apply(preprocess_text)\n",
        "df_test_easy['processed_text'] = df_test_easy['essay_text'].apply(preprocess_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkdkwkoxj6O3"
      },
      "outputs": [],
      "source": [
        "# --- 1. Geração da Matriz TF-IDF Completa (apenas no treino) ---\n",
        "# A matriz TF-IDF deve ser criada a partir do conjunto de treino para evitar vazamento\n",
        "# de dados.\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=stopwords.words('portuguese'))\n",
        "X_train_tfidf_matrix = vectorizer.fit_transform(df_train['processed_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnO1qShqkDbW"
      },
      "outputs": [],
      "source": [
        "# Aplicação do pré-processamento nos textos\n",
        "X_val_tfidf_matrix = vectorizer.transform(df_val['processed_text'])\n",
        "X_test_tfidf_matrix = vectorizer.transform(df_test['processed_text'])\n",
        "X_test_easy_tfidf_matrix = vectorizer.transform(df_test_easy['processed_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGRWkSxNkF1m"
      },
      "outputs": [],
      "source": [
        "# --- 2. Seleção e União dos Índices de Features ---\n",
        "# O número de features a selecionar por competência\n",
        "K_FEATURES_PER_COMPETENCE = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqdqpBKWkI00"
      },
      "outputs": [],
      "source": [
        "# Lista para armazenar os índices das features selecionadas para cada competência\n",
        "selected_features_indices_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8DucTtXkLe8",
        "outputId": "14918c51-de64-4968-8ee8-11bc599ccc2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecionando features para a Competência 1...\n",
            "Selecionando features para a Competência 2...\n",
            "Selecionando features para a Competência 3...\n",
            "Selecionando features para a Competência 4...\n",
            "Selecionando features para a Competência 5...\n"
          ]
        }
      ],
      "source": [
        "for comp_idx in range(1, 6):\n",
        "    print(f\"Selecionando features para a Competência {comp_idx}...\", flush=True)\n",
        "\n",
        "    # Definir a variável alvo (y) para a competência atual no conjunto de treino\n",
        "    y_train_comp = df_train[f'nota_competencia_{comp_idx}_ordinal']\n",
        "\n",
        "    # Ajusta o SelectKBest para encontrar as K_FEATURES_PER_COMPETENCE mais relevantes\n",
        "    selector = SelectKBest(f_classif, k=K_FEATURES_PER_COMPETENCE)\n",
        "    selector.fit(X_train_tfidf_matrix, y_train_comp)\n",
        "\n",
        "    # Adiciona os índices das features selecionadas à lista\n",
        "    selected_features_indices_list.extend(selector.get_support(indices=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDW3vZNOkUPc"
      },
      "outputs": [],
      "source": [
        "# 3. Criar uma lista única de índices e ordenar\n",
        "# O uso de np.unique remove duplicatas caso uma mesma feature seja relevante para\n",
        "# mais de uma competência.\n",
        "unique_selected_indices = np.sort(np.unique(selected_features_indices_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtUpKs5QkfAF"
      },
      "outputs": [],
      "source": [
        "# --- 4. Reduzir as Matrizes TF-IDF Originais ---\n",
        "# Agora, aplicamos a lista de índices unificada a todas as matrizes TF-IDF.\n",
        "X_train_tfidf_final = X_train_tfidf_matrix[:, unique_selected_indices]\n",
        "X_val_tfidf_final = X_val_tfidf_matrix[:, unique_selected_indices]\n",
        "X_test_tfidf_final = X_test_tfidf_matrix[:, unique_selected_indices]\n",
        "X_test_easy_tfidf_final = X_test_easy_tfidf_matrix[:, unique_selected_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYpqODgMkh6t"
      },
      "outputs": [],
      "source": [
        "# Converte para arrays densos, se necessário, para concatenação futura\n",
        "X_train_tfidf_final_array = X_train_tfidf_final.toarray()\n",
        "X_val_tfidf_final_array = X_val_tfidf_final.toarray()\n",
        "X_test_tfidf_final_array = X_test_tfidf_final.toarray()\n",
        "X_test_easy_tfidf_final_array = X_test_easy_tfidf_final.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gon2wYFqks58",
        "outputId": "1f438247-cd3d-4c77-d2e6-345226564399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz TF-IDF final do treino. Dimensão: (758, 3482)\n",
            "Matriz TF-IDF final do teste. Dimensão: (209, 3482)\n",
            "Matriz TF-IDF final da validação. Dimensão: (198, 3482)\n",
            "Matriz TF-IDF final da test easy. Dimensão: (173, 3482)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Matriz TF-IDF final do treino. Dimensão: {X_train_tfidf_final_array.shape}\")\n",
        "print(f\"Matriz TF-IDF final do teste. Dimensão: {X_test_tfidf_final_array.shape}\")\n",
        "print(f\"Matriz TF-IDF final da validação. Dimensão: {X_val_tfidf_final_array.shape}\")\n",
        "print(f\"Matriz TF-IDF final da test easy. Dimensão: {X_test_easy_tfidf_final_array.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento base test inteira"
      ],
      "metadata": {
        "id": "iGAa1Q0zF4D0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM0JFeeoQy19"
      },
      "outputs": [],
      "source": [
        "# --- 4. Loop para Treinar um Modelo para Cada Competência ---\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6): # Para competência 1 a 5\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    # Concatena as features artesanais com as features TF-IDF\n",
        "    X_train =  X_train_tfidf_final_array\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val =  X_val_tfidf_final_array\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_tfidf_final_array\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    # Escalamento de Features (Fit no treino, transform nos outros)\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    # Criar DataModule para a competência atual\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "\n",
        "    # Inicializar e treinar o modelo PyTorch Lightning\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    # Callbacks e Logger\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    # Avaliar no conjunto de teste (avaliação final)\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    # Geração do classification Report\n",
        "    # Obter o modelo treinado\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    # Fazer previsões no conjunto de teste para obter o y_pred\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test # o y_test já foi definido no loop\n",
        "\n",
        "    # Discretizar as previsões para o formato de classe\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    # Gerar os relatórios de classificação\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com Easy test"
      ],
      "metadata": {
        "id": "pt0ur-1KJyiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Loop para Treinar um Modelo para Cada Competência ---\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6): # Para competência 1 a 5\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    # Concatena as features artesanais com as features TF-IDF\n",
        "    X_train =  X_train_tfidf_final_array\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val =  X_val_tfidf_final_array\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_easy_tfidf_final_array\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    # Escalamento de Features (Fit no treino, transform nos outros)\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    # Criar DataModule para a competência atual\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "\n",
        "    # Inicializar e treinar o modelo PyTorch Lightning\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    # Callbacks e Logger\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    # Avaliar no conjunto de teste (avaliação final)\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    # Geração do classification Report\n",
        "    # Obter o modelo treinado\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    # Fazer previsões no conjunto de teste para obter o y_pred\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test # o y_test já foi definido no loop\n",
        "\n",
        "    # Discretizar as previsões para o formato de classe\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    # Gerar os relatórios de classificação\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "LyCHJJ0bJvAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJmzDbPsSYry"
      },
      "source": [
        "# NILC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\", decimal=',')\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\", decimal=',')\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\", decimal=',')\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\", decimal=',')\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\", decimal=',')"
      ],
      "metadata": {
        "id": "615A31R_M6WF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTpxFSlWhbBj"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def prepare_feature_matrix_pure_handcrafted(df):\n",
        "    \"\"\"\n",
        "    Prepara a matriz de features usando apenas as features artesanais.\n",
        "    \"\"\"\n",
        "    print(\"\\nPreparando a matriz de features (X) com Handcrafted Puro...\", flush=True)\n",
        "\n",
        "    # 1. Pré-processar Features Hand-crafted\n",
        "    primeira_coluna_metrica = ' adjective_ratio'\n",
        "    ultima_coluna_metrica = 'ratio_function_to_content_words'\n",
        "    colunas_handcrafted_nomes = df.loc[:, primeira_coluna_metrica:ultima_coluna_metrica].columns.tolist()\n",
        "\n",
        "    for col in colunas_handcrafted_nomes:\n",
        "        if col in df.columns and df[col].dtype == 'object':\n",
        "            df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    handcrafted_features_matrix = df[colunas_handcrafted_nomes].fillna(df[colunas_handcrafted_nomes].mean()).values\n",
        "    X_pure_handcrafted = handcrafted_features_matrix\n",
        "    print(f\"Matriz de features X_pure_handcrafted pronta. Dimensão: {X_pure_handcrafted.shape}\")\n",
        "\n",
        "    return X_pure_handcrafted\n",
        "\n",
        "X_train_handcrafted = prepare_feature_matrix_pure_handcrafted(df_train)\n",
        "X_val_handcrafted = prepare_feature_matrix_pure_handcrafted(df_val)\n",
        "X_test_handcrafted = prepare_feature_matrix_pure_handcrafted(df_test)\n",
        "X_test_easy_handcrafted = prepare_feature_matrix_pure_handcrafted(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com a base teste inteira"
      ],
      "metadata": {
        "id": "GQoG27rPNfzs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJRxjXCqLCcZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_handcrafted\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_handcrafted\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_handcrafted\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com easy test"
      ],
      "metadata": {
        "id": "MD3KFIfRO6V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_handcrafted\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_handcrafted\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_easy_handcrafted\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    # Treinar\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "8pAOZHmoPC_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0MU1yMcyrfF"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZcKkpEayxMK"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\", decimal=',')\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\", decimal=',')\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\", decimal=',')\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\", decimal=',')\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\", decimal=',')\n",
        "\n",
        "def prepare_feature_matrix_pure_bert(df):\n",
        "    \"\"\"\n",
        "    Prepara a matriz de features usando apenas os embeddings do BERT.\n",
        "    \"\"\"\n",
        "    print(\"\\nPreparando a matriz de features (X) com BERT Puro...\", flush=True)\n",
        "\n",
        "    # 1. Pré-processar BERT Embeddings (esta etapa permanece a mesma)\n",
        "    df['bert_embedding'] = df['bert_embedding'].apply(\n",
        "        lambda x: np.array(ast.literal_eval(re.sub(r'\\s+', ',', str(x).strip('[]')).strip(',')))\n",
        "        if pd.notna(x) and isinstance(x, str) and x.strip() else np.zeros(768)\n",
        "    )\n",
        "    bert_embeddings_matrix = np.stack(df['bert_embedding'].values)\n",
        "\n",
        "    # 3. Retorne apenas a matriz de embeddings do BERT\n",
        "    X_pure_bert = bert_embeddings_matrix\n",
        "    print(f\"Matriz de features X_pure_bert pronta. Dimensão: {X_pure_bert.shape}\")\n",
        "\n",
        "    return X_pure_bert\n",
        "\n",
        "# Passo 2: Aplicar a função a cada DataFrame para obter as matrizes X\n",
        "# Os nomes das variáveis foram alterados para refletir a abordagem pura\n",
        "X_train_pure = prepare_feature_matrix_pure_bert(df_train)\n",
        "X_val_pure = prepare_feature_matrix_pure_bert(df_val)\n",
        "X_test_pure = prepare_feature_matrix_pure_bert(df_test)\n",
        "X_test_easy_pure = prepare_feature_matrix_pure_bert(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com toda base de teste"
      ],
      "metadata": {
        "id": "qaMFA0X0EkMb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTz6QsZPy2eZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_pure\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_pure\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_pure\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento apenas com easy test"
      ],
      "metadata": {
        "id": "r1cKT9MjEuiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_pure\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_pure\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_easy_pure\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "3Q7U4acbEsR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpR8i-cplwuP"
      },
      "source": [
        "# Murilo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjX8p6I3lzO0"
      },
      "outputs": [],
      "source": [
        "df_murilo_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/train_murilo.csv\")\n",
        "df_murilo_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/validation_murilo.csv\")\n",
        "df_murilo_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/test_murilo.csv\")\n",
        "df_murilo_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/df features Murilo/df_murilo_test_easy.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAiwHNxd3ZVd"
      },
      "outputs": [],
      "source": [
        "nota_total_col = 'nota_total'\n",
        "competencia_cols = ['nota_c1', 'nota_c2', 'nota_c3', 'nota_c4', 'nota_c5']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeKXDSGJlCd7"
      },
      "outputs": [],
      "source": [
        "def mapeamento_ordinal(df):\n",
        "    # Dicionário que mapeia a nota real para o valor ordinal\n",
        "    mapeamento_competencia_ordinal = {\n",
        "        0: 0,\n",
        "        40: 1,\n",
        "        80: 2,\n",
        "        120: 3,\n",
        "        160: 4,\n",
        "        200: 5\n",
        "    }\n",
        "\n",
        "    for col_name in competencia_cols:\n",
        "        df[f'{col_name}_ordinal'] = df[col_name].map(mapeamento_competencia_ordinal)\n",
        "    return df\n",
        "\n",
        "df_test = mapeamento_ordinal(df_murilo_test)\n",
        "df_train = mapeamento_ordinal(df_murilo_train)\n",
        "df_val = mapeamento_ordinal(df_murilo_val)\n",
        "df_test_easy = mapeamento_ordinal(df_murilo_test_easy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMckhs72ldIe"
      },
      "outputs": [],
      "source": [
        "def prepare_feature_matrix_pure_handcrafted(df):\n",
        "    \"\"\"\n",
        "    Prepara a matriz de features usando apenas as features artesanais.\n",
        "    \"\"\"\n",
        "\n",
        "    primeira_coluna_metrica = 'n_verbos_e_pronomes_1ps'\n",
        "    ultima_coluna_metrica = 'similaridade_tit_1_constituicao_bertimbau'\n",
        "    colunas_handcrafted_nomes = df.loc[:, primeira_coluna_metrica:ultima_coluna_metrica].columns.tolist()\n",
        "\n",
        "    for col in colunas_handcrafted_nomes:\n",
        "        if col in df.columns and df[col].dtype == 'object':\n",
        "            df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    handcrafted_features_matrix = df[colunas_handcrafted_nomes].fillna(df[colunas_handcrafted_nomes].mean()).values\n",
        "\n",
        "    X_pure_handcrafted = handcrafted_features_matrix\n",
        "    # print(f\"Matriz de features X_pure_handcrafted pronta. Dimensão: {X_pure_handcrafted.shape}\")\n",
        "\n",
        "    return X_pure_handcrafted\n",
        "\n",
        "# Passo 2: Aplicar a função a cada DataFrame para obter as matrizes X\n",
        "X_train_handcrafted_Murilo = prepare_feature_matrix_pure_handcrafted(df_train)\n",
        "X_val_handcrafted_Murilo = prepare_feature_matrix_pure_handcrafted(df_val)\n",
        "X_test_handcrafted_Murilo = prepare_feature_matrix_pure_handcrafted(df_test)\n",
        "X_test_easy_handcrafted_Murilo = prepare_feature_matrix_pure_handcrafted(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test inteira"
      ],
      "metadata": {
        "id": "sJs96CZIOzS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zr3oHbQVlwuQ"
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "    y_train_series = df_train[f'nota_c{comp_idx}_ordinal']\n",
        "    y_val_series = df_val[f'nota_c{comp_idx}_ordinal']\n",
        "    y_test_series = df_test[f'nota_c{comp_idx}_ordinal']\n",
        "\n",
        "    X_train = X_train_handcrafted_Murilo\n",
        "    y_train = df_train[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_train = y_train_series.fillna(0).astype(int).values\n",
        "\n",
        "    X_val = X_val_handcrafted_Murilo\n",
        "    y_val = df_val[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_val = y_val_series.fillna(0).astype(int).values\n",
        "\n",
        "    X_test = X_test_handcrafted_Murilo\n",
        "    y_test = df_test[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_test = y_test_series.fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento easy test"
      ],
      "metadata": {
        "id": "czEzRsC9O-od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "    y_train_series = df_train[f'nota_c{comp_idx}_ordinal']\n",
        "    y_val_series = df_val[f'nota_c{comp_idx}_ordinal']\n",
        "    y_test_series = df_test_easy[f'nota_c{comp_idx}_ordinal']\n",
        "\n",
        "    X_train = X_train_handcrafted_Murilo\n",
        "    y_train = df_train[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_train = y_train_series.fillna(0).astype(int).values\n",
        "\n",
        "    X_val = X_val_handcrafted_Murilo\n",
        "    y_val = df_val[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_val = y_val_series.fillna(0).astype(int).values\n",
        "\n",
        "    X_test = X_test_easy_handcrafted_Murilo\n",
        "    y_test = df_test_easy[f'nota_c{comp_idx}_ordinal'].values\n",
        "    y_test = y_test_series.fillna(0).astype(int).values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "aPuWca3TO-Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0x03reKDj0n"
      },
      "source": [
        "# TF-IDF + NILC  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FJEGzC9Flg-"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\")\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")\n",
        "\n",
        "def prepare_feature_matrix_pure_handcrafted(df):\n",
        "\n",
        "    primeira_coluna_metrica = ' adjective_ratio'\n",
        "    ultima_coluna_metrica = 'ratio_function_to_content_words'\n",
        "    colunas_handcrafted_nomes = df.loc[:, primeira_coluna_metrica:ultima_coluna_metrica].columns.tolist()\n",
        "\n",
        "    for col in colunas_handcrafted_nomes:\n",
        "        if col in df.columns and df[col].dtype == 'object':\n",
        "            df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    handcrafted_features_matrix = df[colunas_handcrafted_nomes].fillna(df[colunas_handcrafted_nomes].mean()).values\n",
        "\n",
        "    X_pure_handcrafted = handcrafted_features_matrix\n",
        "    print(f\"Matriz de features X_pure_handcrafted pronta. Dimensão: {X_pure_handcrafted.shape}\")\n",
        "\n",
        "    return X_pure_handcrafted\n",
        "\n",
        "X_train_handcrafted = prepare_feature_matrix_pure_handcrafted(df_train)\n",
        "X_val_handcrafted = prepare_feature_matrix_pure_handcrafted(df_val)\n",
        "X_test_handcrafted = prepare_feature_matrix_pure_handcrafted(df_test)\n",
        "X_test_easy_handcrafted = prepare_feature_matrix_pure_handcrafted(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento base teste inteira"
      ],
      "metadata": {
        "id": "0ATnQbzyGsQY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV4zqxkbFvcV"
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted, X_test_tfidf_final_array))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento teste easy"
      ],
      "metadata": {
        "id": "ePXcUUVuGz9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted, X_test_easy_tfidf_final_array))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "ZC4YRsiVG2o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xhzol4FS3jp"
      },
      "source": [
        "# TF-IDF + BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G20j6wxkS-Ff"
      },
      "outputs": [],
      "source": [
        "# # Importação dos dataframes\n",
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "# df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\")\n",
        "# df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")\n",
        "\n",
        "# def prepare_feature_matrix_pure_bert(df):\n",
        "#     df['bert_embedding'] = df['bert_embedding'].apply(\n",
        "#         lambda x: np.array(ast.literal_eval(re.sub(r'\\s+', ',', str(x).strip('[]')).strip(',')))\n",
        "#         if pd.notna(x) and isinstance(x, str) and x.strip() else np.zeros(768)\n",
        "#     )\n",
        "#     bert_embeddings_matrix = np.stack(df['bert_embedding'].values)\n",
        "\n",
        "#     X_pure_bert = bert_embeddings_matrix\n",
        "#     print(f\"Matriz de features X_pure_bert pronta. Dimensão: {X_pure_bert.shape}\")\n",
        "\n",
        "#     return X_pure_bert\n",
        "# X_train_pure = prepare_feature_matrix_pure_bert(df_train)\n",
        "# X_val_pure = prepare_feature_matrix_pure_bert(df_val)\n",
        "# X_test_pure = prepare_feature_matrix_pure_bert(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com a base teste inteira"
      ],
      "metadata": {
        "id": "kGA8US-6I8rc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8NtVCXCTC4f",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_pure, X_test_tfidf_final_array))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento com teste easy"
      ],
      "metadata": {
        "id": "9F4MeGXZJI9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_pure, X_test_easy_tfidf_final_array))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "7CTqQdvrJLEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icNvU_I1zj6x"
      },
      "source": [
        "# TF-IDF + Murilo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento base test inteira"
      ],
      "metadata": {
        "id": "PBUSQlGwPldF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NwMbDfMQQue9"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted_Murilo, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted_Murilo, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted_Murilo, X_test_tfidf_final_array))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento easy test"
      ],
      "metadata": {
        "id": "_aHCA2xYPtIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted_Murilo, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted_Murilo, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted_Murilo, X_test_easy_tfidf_final_array))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "YDbibFjwPr0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9Qj8PYb-PjP"
      },
      "source": [
        "# NILC + BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNlCSucwKxQa"
      },
      "outputs": [],
      "source": [
        "# Importação dos dataframes\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_train.csv\")\n",
        "df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_val.csv\")\n",
        "df_test_easy = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_easy.csv\")\n",
        "df_test_hard = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/test easy and hard/df_test_hard.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/Base correta/NILC + Embedding + ORD (final df)/df_test.csv\")\n",
        "\n",
        "def prepare_feature_matrix(df):\n",
        "    df['bert_embedding'] = df['bert_embedding'].apply(\n",
        "        lambda x: np.array(ast.literal_eval(re.sub(r'\\s+', ',', str(x).strip('[]')).strip(',')))\n",
        "        if pd.notna(x) and isinstance(x, str) and x.strip() else np.zeros(768)\n",
        "    )\n",
        "    bert_embeddings_matrix = np.stack(df['bert_embedding'].values)\n",
        "\n",
        "    primeira_coluna_metrica = ' adjective_ratio'\n",
        "    ultima_coluna_metrica = 'ratio_function_to_content_words'\n",
        "    colunas_handcrafted_nomes = df.loc[:, primeira_coluna_metrica:ultima_coluna_metrica].columns.tolist()\n",
        "\n",
        "    for col in colunas_handcrafted_nomes:\n",
        "        if col in df.columns and df[col].dtype == 'object':\n",
        "            df[col] = df[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    handcrafted_features_matrix = df[colunas_handcrafted_nomes].fillna(df[colunas_handcrafted_nomes].mean()).values\n",
        "\n",
        "    X_combined = np.hstack((bert_embeddings_matrix, handcrafted_features_matrix))\n",
        "    print(f\"Matriz de features X_combined pronta. Dimensão: {X_combined.shape}\")\n",
        "\n",
        "    return X_combined\n",
        "\n",
        "X_train_combined = prepare_feature_matrix(df_train)\n",
        "X_val_combined = prepare_feature_matrix(df_val)\n",
        "X_test_combined = prepare_feature_matrix(df_test)\n",
        "X_test_easy_combined = prepare_feature_matrix(df_test_easy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base teste inteira"
      ],
      "metadata": {
        "id": "BVw4gDVnKevt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nsX0KXqd9IR"
      },
      "outputs": [],
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\" #\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_combined\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_combined\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_combined\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base easy"
      ],
      "metadata": {
        "id": "7l-NBG09Km-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\" #\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = X_train_combined\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = X_val_combined\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = X_test_easy_combined\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "XqJ0SjTPKtaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2Q4PcRc1xYz"
      },
      "source": [
        "# NILC + Murilo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test inteira"
      ],
      "metadata": {
        "id": "aoHlAXo2P9he"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcVCOpw7kQoJ"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento easy test"
      ],
      "metadata": {
        "id": "zIQJ7xalQHUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "LzVuU8mBQLLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5VKkj742HSt"
      },
      "source": [
        "# BERT + Murilo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test inteira"
      ],
      "metadata": {
        "id": "FFa8_ZIRQtcW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peE0gWSYlFv3"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_pure, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#treinamento easy test"
      ],
      "metadata": {
        "id": "TpIhc_lpQyet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_pure, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "icpe48oBQ16g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKVQ_fbTN7XN"
      },
      "source": [
        "# TF-IDF + NILC + BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pc_LcxaOLEt"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_combined, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_combined, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_combined, X_test_tfidf_final_array))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base easy"
      ],
      "metadata": {
        "id": "enHnsoT4LFUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_combined, X_train_tfidf_final_array))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_combined, X_val_tfidf_final_array))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_combined, X_test_easy_tfidf_final_array))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "JV3aeL-VLHe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvIotJtLJFDB"
      },
      "source": [
        "# TF IDF + NILC + Murilo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test inteira"
      ],
      "metadata": {
        "id": "CuOAv9riRRWf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0-X2WdqJONY"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted, X_test_tfidf_final_array, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "treinamento base test easy"
      ],
      "metadata": {
        "id": "UnLPRzylRXh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted, X_test_easy_tfidf_final_array, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "xItkw0wrRZxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HsYfeRAFmun"
      },
      "source": [
        "# TF IDF + BERT + Murilo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZS6Qv40lbOH"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_tfidf_final_array, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_tfidf_final_array, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_pure, X_test_tfidf_final_array, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste easy"
      ],
      "metadata": {
        "id": "WNAsMvVJTON8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_tfidf_final_array, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_tfidf_final_array, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_pure, X_test_easy_tfidf_final_array, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "geIwH83pTQkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3qUt7Z5F3-g"
      },
      "source": [
        "# NILC + BERT + Murilo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V3xt76vmV-2"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_handcrafted, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_handcrafted, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_pure, X_test_handcrafted, X_test_handcrafted_Murilo))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test easy"
      ],
      "metadata": {
        "id": "eJsby4pHTldb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_pure, X_train_handcrafted, X_train_handcrafted_Murilo))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_pure, X_val_handcrafted, X_val_handcrafted_Murilo))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_pure, X_test_easy_handcrafted, X_test_easy_handcrafted_Murilo))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "O-QXCUjYTm1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Q6qpwOwvtJ"
      },
      "source": [
        "# TF IDF + NILC + BERT + Murilo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyAFTMs3Kygn"
      },
      "outputs": [],
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array, X_train_handcrafted_Murilo, X_train_pure))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array, X_val_handcrafted_Murilo, X_val_pure))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_handcrafted, X_test_tfidf_final_array, X_test_handcrafted_Murilo, X_test_pure))\n",
        "    y_test = df_test[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste easy"
      ],
      "metadata": {
        "id": "Fcyxpw73T0rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_train.csv\")\n",
        "# df_val = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_validation.csv\")\n",
        "# df_test = pd.read_csv(\"/content/drive/MyDrive/TCC -  Bacharel  Informática/Arquivos desenvolvimento/Base de dados/DataFrame/Df text + metrics + embeddings + vet_ordinal/df_test.csv\")\n",
        "\n",
        "resultados_por_competencia = {}\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "for comp_idx in range(1, 6):\n",
        "    print(f\"\\n--- Treinando Modelo para Competência {comp_idx} ---\", flush=True)\n",
        "\n",
        "    X_train = np.hstack((X_train_handcrafted, X_train_tfidf_final_array, X_train_handcrafted_Murilo, X_train_pure))\n",
        "    y_train = df_train[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_val = np.hstack((X_val_handcrafted, X_val_tfidf_final_array, X_val_handcrafted_Murilo, X_val_pure))\n",
        "    y_val = df_val[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    X_test = np.hstack((X_test_easy_handcrafted, X_test_easy_tfidf_final_array, X_test_easy_handcrafted_Murilo, X_test_easy_pure))\n",
        "    y_test = df_test_easy[f'nota_competencia_{comp_idx}_ordinal'].values\n",
        "\n",
        "    print(f\"Divisão de dados para Competência {comp_idx}: Treino={X_train.shape}, Validação={X_val.shape}, Teste={X_test.shape}\", flush=True)\n",
        "\n",
        "    scaler_comp = StandardScaler()\n",
        "    X_train_std = scaler_comp.fit_transform(X_train)\n",
        "    X_val_std = scaler_comp.transform(X_val)\n",
        "    X_test_std = scaler_comp.transform(X_test)\n",
        "    print(f\"Features escaladas para Competência {comp_idx}.\", flush=True)\n",
        "\n",
        "    data_module_competencia = CompetenceDataModule(X_train_std, y_train, X_val_std, y_val, X_test_std, y_test, BATCH_SIZE, NUM_WORKERS)\n",
        "    data_module_competencia.setup()\n",
        "\n",
        "    input_dim = X_train_std.shape[1]\n",
        "\n",
        "    pytorch_model_competencia = MultiLayerPerceptron(\n",
        "        input_size=input_dim,\n",
        "        hidden_units=(256, 128, 64),\n",
        "        num_classes=NUM_CLASSES_COMPETENCIA\n",
        "    )\n",
        "    lightning_model_competencia = LightningMLP(\n",
        "        model=pytorch_model_competencia,\n",
        "        learning_rate=LEARNING_RATE\n",
        "    )\n",
        "\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        save_top_k=1, mode=\"min\", monitor=\"valid_mae\",\n",
        "        dirpath=f\"logs_comp_{comp_idx}/\", filename=f\"best_model_comp_{comp_idx}\"\n",
        "    )\n",
        "    logger_competencia = CSVLogger(save_dir=\"logs/\", name=f\"mlp-coral-comp-{comp_idx}\")\n",
        "\n",
        "\n",
        "    early_stop_callback = EarlyStopping(\n",
        "    monitor=\"valid_qwk\",\n",
        "    min_delta=0.00,\n",
        "    patience=50,\n",
        "    verbose=True,\n",
        "    mode=\"max\"\n",
        "    )\n",
        "\n",
        "    callbacks_list = [\n",
        "        model_checkpoint_callback,\n",
        "        early_stop_callback\n",
        "    ]\n",
        "\n",
        "    trainer_competencia = pl.Trainer(\n",
        "        max_epochs=NUM_EPOCHS,\n",
        "        callbacks=callbacks_list,\n",
        "        accelerator=device_type,\n",
        "        devices=1,\n",
        "        logger=logger_competencia,\n",
        "        deterministic=True,\n",
        "        log_every_n_steps=10\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    print(f\"Treinando modelo para Competência {comp_idx}...\", flush=True)\n",
        "    trainer_competencia.fit(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    runtime = (time.time() - start_time)/60\n",
        "    print(f\"Treinamento para Competência {comp_idx} levou {runtime:.2f} min.\", flush=True)\n",
        "\n",
        "    print(f\"Avaliando modelo para Competência {comp_idx} no conjunto de teste...\", flush=True)\n",
        "    test_results = trainer_competencia.test(model=lightning_model_competencia, datamodule=data_module_competencia)\n",
        "    resultados_por_competencia[f'competencia_{comp_idx}'] = test_results[0]\n",
        "\n",
        "    model_path = model_checkpoint_callback.best_model_path\n",
        "    best_model = LightningMLP.load_from_checkpoint(model_path, model=pytorch_model_competencia, learning_rate=LEARNING_RATE)\n",
        "    best_model.eval()\n",
        "\n",
        "    y_pred_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_module_competencia.test_dataloader():\n",
        "            features, _ = batch\n",
        "            logits = best_model(features)\n",
        "            probas = torch.sigmoid(logits)\n",
        "            predicted_labels = proba_to_label(probas)\n",
        "            y_pred_list.append(predicted_labels.cpu().numpy())\n",
        "\n",
        "    y_pred = np.hstack(y_pred_list)\n",
        "    y_true = y_test\n",
        "\n",
        "    y_pred_discreto = np.clip(np.round(y_pred), 0, NUM_CLASSES_COMPETENCIA - 1).astype(int)\n",
        "\n",
        "    print(\"--- Relatório de Classificação da Competência \", comp_idx, \" ---\")\n",
        "    print(classification_report(y_true, y_pred_discreto, zero_division=0.0))\n",
        "    print(\"\\n--- Matriz de Confusão da Competência \", comp_idx, \" ---\")\n",
        "    print(confusion_matrix(y_true, y_pred_discreto))\n",
        "\n",
        "    print(f\"--- Modelo para Competência {comp_idx} concluído ---\", flush=True)\n",
        "\n",
        "print(\"\\n--- Todos os modelos de competência foram treinados e avaliados ---\", flush=True)\n",
        "for comp, results in resultados_por_competencia.items():\n",
        "    print(f\"{comp}: QWK = {results['test_qwk']:.4f}, RMSE = {results['test_rmse']:.4f}, HDIV = {1- results['test_enem_acc']:.4f}\", flush=True)"
      ],
      "metadata": {
        "id": "7M-GR4QwT2on"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "neyIHZ4sV7c0",
        "v8cWBuX7avcA",
        "al-3J8En5enw",
        "dZYW-Jsu3RtE",
        "PpR3-rOG5sX1",
        "Luqc3udpwAX5",
        "BAt8GrhA8fin",
        "RWNec_aT8vNY",
        "sJmzDbPsSYry",
        "HpR8i-cplwuP",
        "D0x03reKDj0n",
        "5Xhzol4FS3jp",
        "icNvU_I1zj6x",
        "U9Qj8PYb-PjP",
        "v2Q4PcRc1xYz",
        "C5VKkj742HSt",
        "FKVQ_fbTN7XN",
        "gvIotJtLJFDB",
        "0HsYfeRAFmun",
        "Q3qUt7Z5F3-g"
      ],
      "provenance": [],
      "mount_file_id": "1i5-vPwnxR9NwmAXD3RX11bpoyHRmI6QP",
      "authorship_tag": "ABX9TyPb/UiJ5OISDiCqSTnwHM4S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ddf913a04e1448e0a20ff2475c90371c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33ddb8eaee5840ffb7354cbd2739a3fd",
              "IPY_MODEL_4560345e9fe34f0cac020647be8bf097",
              "IPY_MODEL_4638a22cf9d14283a3183c56427787c7"
            ],
            "layout": "IPY_MODEL_f71eafd10c1d4a4dab3562880aac0add"
          }
        },
        "33ddb8eaee5840ffb7354cbd2739a3fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e192c36a5e4e44bfcfdb1011cf7976",
            "placeholder": "​",
            "style": "IPY_MODEL_9e3fb699c8794ec3a2eca967bdd751d1",
            "value": "README.md: "
          }
        },
        "4560345e9fe34f0cac020647be8bf097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0252174812724a73885e663710af5505",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca826f84b25c422790f84ffb31b938d2",
            "value": 1
          }
        },
        "4638a22cf9d14283a3183c56427787c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba599b2e91d143148e8f191668af6630",
            "placeholder": "​",
            "style": "IPY_MODEL_f27e6f567b094ecfad52072c120a49ee",
            "value": " 7.27k/? [00:00&lt;00:00, 299kB/s]"
          }
        },
        "f71eafd10c1d4a4dab3562880aac0add": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e192c36a5e4e44bfcfdb1011cf7976": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e3fb699c8794ec3a2eca967bdd751d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0252174812724a73885e663710af5505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ca826f84b25c422790f84ffb31b938d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba599b2e91d143148e8f191668af6630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f27e6f567b094ecfad52072c120a49ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41fbed63d24d4930bba2be31842a8e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_178ed08adee54dc0bd884f7bde781f3d",
              "IPY_MODEL_d9e39bbef0934a5d9c7d844812a54102",
              "IPY_MODEL_f264678305a84e998529df9e6d029bc8"
            ],
            "layout": "IPY_MODEL_c50e994e93524687946bb075b31f5de5"
          }
        },
        "178ed08adee54dc0bd884f7bde781f3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d95282c73b946b6a29932cd4014c80b",
            "placeholder": "​",
            "style": "IPY_MODEL_2280c4e64ac94e918160e94b3b189e97",
            "value": "sourceAWithGraders/train-00000-of-00001.(…): 100%"
          }
        },
        "d9e39bbef0934a5d9c7d844812a54102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7177bfe381964370a34912158506fd18",
            "max": 588849,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1a2dc165bed44b1952815fa6af4ce20",
            "value": 588849
          }
        },
        "f264678305a84e998529df9e6d029bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa51267bfb5c42b5b26e560d64e58ea0",
            "placeholder": "​",
            "style": "IPY_MODEL_f4595f36fadc4d53ba53a0f88f1706a1",
            "value": " 589k/589k [00:03&lt;00:00, 171kB/s]"
          }
        },
        "c50e994e93524687946bb075b31f5de5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d95282c73b946b6a29932cd4014c80b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2280c4e64ac94e918160e94b3b189e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7177bfe381964370a34912158506fd18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a2dc165bed44b1952815fa6af4ce20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa51267bfb5c42b5b26e560d64e58ea0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4595f36fadc4d53ba53a0f88f1706a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cecff74e4d2b42b1a7a77295fbd4c432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83d15e315ebe4d1b947ea63a36ed29cc",
              "IPY_MODEL_d4bfc9b6ea694fecbc452cfa4f8c8bca",
              "IPY_MODEL_47593ada5106488b9298fe2a35782b9b"
            ],
            "layout": "IPY_MODEL_3b19d6393f2249d190d3013f175f4bb6"
          }
        },
        "83d15e315ebe4d1b947ea63a36ed29cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_059ee0ef13b246588b1c9b25218f9711",
            "placeholder": "​",
            "style": "IPY_MODEL_92cb0bcd5a2f4e278f485aba0c68e0f4",
            "value": "sourceAWithGraders/validation-00000-of-0(…): 100%"
          }
        },
        "d4bfc9b6ea694fecbc452cfa4f8c8bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e35b1c576944e31a4381ec2bf33fb78",
            "max": 162606,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8607fd04cdf54eba90ca0fc04dc1c1ee",
            "value": 162606
          }
        },
        "47593ada5106488b9298fe2a35782b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beccb68f585b495d808a210a6025084c",
            "placeholder": "​",
            "style": "IPY_MODEL_c75ddb474a2845bf966511dfadda079c",
            "value": " 163k/163k [00:02&lt;00:00, 78.9kB/s]"
          }
        },
        "3b19d6393f2249d190d3013f175f4bb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "059ee0ef13b246588b1c9b25218f9711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92cb0bcd5a2f4e278f485aba0c68e0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e35b1c576944e31a4381ec2bf33fb78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8607fd04cdf54eba90ca0fc04dc1c1ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "beccb68f585b495d808a210a6025084c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c75ddb474a2845bf966511dfadda079c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d601a182de648539a3c1b6985088721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34608d5a1bd44199a20123dc4e206057",
              "IPY_MODEL_fb35f5ce50454525a2378421caa001ca",
              "IPY_MODEL_37fd4e2a817344f081cf34e9e33f760e"
            ],
            "layout": "IPY_MODEL_5baeb20a1e324783805125e65b84085a"
          }
        },
        "34608d5a1bd44199a20123dc4e206057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0d5f852db6440d387ea9fb1f5986e88",
            "placeholder": "​",
            "style": "IPY_MODEL_f1a0170205a04034ae148579cf03774c",
            "value": "sourceAWithGraders/test-00000-of-00001.p(…): 100%"
          }
        },
        "fb35f5ce50454525a2378421caa001ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e641d7696864983a76c3e3131885144",
            "max": 178039,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1fe54a67ca74122ab06b3ef5921fca6",
            "value": 178039
          }
        },
        "37fd4e2a817344f081cf34e9e33f760e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d3faf6be0b44f583cb18fff98a5079",
            "placeholder": "​",
            "style": "IPY_MODEL_cbae534709cf432dbdd7ae241cb38b5e",
            "value": " 178k/178k [00:02&lt;00:00, 79.3kB/s]"
          }
        },
        "5baeb20a1e324783805125e65b84085a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d5f852db6440d387ea9fb1f5986e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a0170205a04034ae148579cf03774c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e641d7696864983a76c3e3131885144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1fe54a67ca74122ab06b3ef5921fca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5d3faf6be0b44f583cb18fff98a5079": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbae534709cf432dbdd7ae241cb38b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83625cf9a4f541489b9340628b969c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb0f90396e644e9681016b24bcf403ee",
              "IPY_MODEL_408c8ffb515341d7a315ec9cd67190fd",
              "IPY_MODEL_6f85d79ac9134876953fe16224a64025"
            ],
            "layout": "IPY_MODEL_8d9acd0f4364414a8694fa7d38d7a1c5"
          }
        },
        "cb0f90396e644e9681016b24bcf403ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ec4a6dbccb34618bdd574b507e21c34",
            "placeholder": "​",
            "style": "IPY_MODEL_fe295d967e7f4df4bfa53ee7dd418229",
            "value": "Generating train split: 100%"
          }
        },
        "408c8ffb515341d7a315ec9cd67190fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d01718dffd46d786f3d44f55cf22ad",
            "max": 758,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05eff5d01a634ebab68ab6507df53c89",
            "value": 758
          }
        },
        "6f85d79ac9134876953fe16224a64025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c52f7ee14caf403a9b352ac9ee861f7e",
            "placeholder": "​",
            "style": "IPY_MODEL_6adfb288487b46c190879e4a98577e56",
            "value": " 758/758 [00:00&lt;00:00, 6612.62 examples/s]"
          }
        },
        "8d9acd0f4364414a8694fa7d38d7a1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec4a6dbccb34618bdd574b507e21c34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe295d967e7f4df4bfa53ee7dd418229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7d01718dffd46d786f3d44f55cf22ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05eff5d01a634ebab68ab6507df53c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c52f7ee14caf403a9b352ac9ee861f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6adfb288487b46c190879e4a98577e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51e5e7e13fbf4d83afa48b0da5ad36fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03b927f95f3d489b900252ceb552c9c3",
              "IPY_MODEL_9f2876c84ef84852988bed8096eb240a",
              "IPY_MODEL_a41308c1b1ba47bda8343b2f8db7283c"
            ],
            "layout": "IPY_MODEL_b32ccd0775d0413f86aceef124fb78f5"
          }
        },
        "03b927f95f3d489b900252ceb552c9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5881870aa125482eab86f48b816efec2",
            "placeholder": "​",
            "style": "IPY_MODEL_e84ce443daba47ef9da780069017f040",
            "value": "Generating validation split: 100%"
          }
        },
        "9f2876c84ef84852988bed8096eb240a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e1fe32865a44975bb0f1ae981ceb1ab",
            "max": 198,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70f4e504680e41b4aee3a63509f257f0",
            "value": 198
          }
        },
        "a41308c1b1ba47bda8343b2f8db7283c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff39f37d48b4cee89dcddb6a41f3d19",
            "placeholder": "​",
            "style": "IPY_MODEL_bd5a681dd223428290b7ef96e94b977f",
            "value": " 198/198 [00:00&lt;00:00, 6395.92 examples/s]"
          }
        },
        "b32ccd0775d0413f86aceef124fb78f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5881870aa125482eab86f48b816efec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84ce443daba47ef9da780069017f040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e1fe32865a44975bb0f1ae981ceb1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70f4e504680e41b4aee3a63509f257f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ff39f37d48b4cee89dcddb6a41f3d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd5a681dd223428290b7ef96e94b977f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f29814ca434e49abbe70bbf35d69d54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edb419b75a5b405b9eed9d07d4c7b47e",
              "IPY_MODEL_416190b0f97e4509a502c68fe116a55a",
              "IPY_MODEL_93eec2d156d04eff9329e3facc509db9"
            ],
            "layout": "IPY_MODEL_3bcc7151c37742619930e3f2e19f7539"
          }
        },
        "edb419b75a5b405b9eed9d07d4c7b47e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aa9997173414fb89278a8765102a8d3",
            "placeholder": "​",
            "style": "IPY_MODEL_c084df03093d4e03ad9a987773933b78",
            "value": "Generating test split: 100%"
          }
        },
        "416190b0f97e4509a502c68fe116a55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdf66fe5b26247b18085ab22ef3a8145",
            "max": 209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71e9fb2e393f413f9ecea75bec5b9498",
            "value": 209
          }
        },
        "93eec2d156d04eff9329e3facc509db9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72402864b0e24a79b58b4cae8f4f3fdd",
            "placeholder": "​",
            "style": "IPY_MODEL_4531c383dbcf4d1b9c57a80883dcbf6d",
            "value": " 209/209 [00:00&lt;00:00, 7465.78 examples/s]"
          }
        },
        "3bcc7151c37742619930e3f2e19f7539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aa9997173414fb89278a8765102a8d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c084df03093d4e03ad9a987773933b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdf66fe5b26247b18085ab22ef3a8145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71e9fb2e393f413f9ecea75bec5b9498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72402864b0e24a79b58b4cae8f4f3fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4531c383dbcf4d1b9c57a80883dcbf6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}